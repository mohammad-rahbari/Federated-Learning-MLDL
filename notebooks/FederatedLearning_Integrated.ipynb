{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-rahbari/Federated-Learning-MLDL/blob/master/notebooks/FederatedLearning_Integrated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBf85ZRGj6HO",
        "outputId": "639c646d-ba17-4df3-c121-43b430d9c134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu0Iz0LDlRDK"
      },
      "source": [
        "# Importing DINO and installing its dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IckKkLcG0zeA",
        "outputId": "5b02151d-21d7-4625-a953-57024b173718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dino'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Total 175 (delta 0), reused 0 (delta 0), pack-reused 175 (from 1)\u001b[K\n",
            "Receiving objects: 100% (175/175), 24.47 MiB | 17.42 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ],
      "source": [
        "# @title Clon the DINO ripo\n",
        "!git clone https://github.com/facebookresearch/dino.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dY0yvkTfiNV3",
        "outputId": "6b67be36-cfc1-4c69-a508-b67805f32232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dino\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.19)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.34.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "# @title Installing required dependencies regarding DINO\n",
        "%cd dino\n",
        "!pip install -r requirements.txt\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dDodXJD_lPCd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split,DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9hv0ik3jZ-8"
      },
      "source": [
        "\n",
        "# preprocessing the CIFAR-100 dataset\n",
        "\n",
        "feature size in CIFAR is 32x32 but DINO requires 224x224 in the input layer.\n",
        "\n",
        "In first step we upscale the dataset and then we add randomization to it\n",
        "\n",
        "In last step of transformation we normalize data usind mean value and standard division of ImageNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_4ydT67FmAQR"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNgGMkqaqX-G",
        "outputId": "a54e8937-f7dc-4656-9c75-12994d5481ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:03<00:00, 43.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of combined dataset: 50000\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "import numpy as np\n",
        "from torchvision.datasets import CIFAR100\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "full_train = train_dataset\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, num_workers=2)\n",
        "# Verify the length of the new dataset\n",
        "print(f\"Length of combined dataset: {len(full_train)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dNQ67lu7cYNj"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Imports\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4oXrqMHwAit"
      },
      "source": [
        "# Set Hyperparameters regarding the data spliting here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VJfqNlD_ORqk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title set the parameters here!!\n",
        "\n",
        "\n",
        "\n",
        "number_of_clients = None\n",
        "train_frac = 1 #@param\n",
        "val_frac = 0 #@param\n",
        "batch_size = 32 #@param{type:\"integer\"}\n",
        "is_seed_fixed = True #@param{type:\"boolean\"}\n",
        "seed = 42 #@param{type:\"integer\"}\n",
        "\n",
        "def set_seed(seed=42, is_seed_fixed=True):\n",
        "  if not is_seed_fixed:\n",
        "    return\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seed(seed,is_seed_fixed)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown </br> <h5>Indicate the number of clients that contribute in training:</h5>\n",
        "n_clients = 100 #@param{type:\"integer\"}\n",
        "\n",
        "#@markdown </br></br> <b>splitting hyperparameters</b>\n",
        "\n",
        "spliting_method = \"i.i.d. sharing\" #@param[\"i.i.d. sharing\",\"non-i.i.d. sharing\"]\n",
        "backbone = \"dino_vits16\" #@param[\"dino_resnet50\", \"dino_vits16\", \"dino_xcit_small_12_p16\"]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W4gR7IvnxqL6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Set the parameters here only if <b>non-i.i.d. sharing</b> method had been selected!!\n",
        "#@markdown Nc is the number of classes that each subset can contain\n",
        "if spliting_method == \"non-i.i.d. sharing\":\n",
        "  Nc = 25 #@param{type:\"integer\"}\n",
        "\n",
        "  # are_classes_overlaping = False #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown <h3>If we consider the Number of classes M and nummber of client K then:</h3>\n",
        "#@markdown <ul>\n",
        "#@markdown   <li>Nc should be:\n",
        "#@markdown     <ul>\n",
        "#@markdown       <li>\n",
        "#@markdown         Greater than or equal to <b>\\\\(\\frac{M}{K}\\\\)</b>\n",
        "#@markdown       </li>\n",
        "#@markdown       <li>\n",
        "#@markdown         Less than or equal to K </b>\n",
        "#@markdown       </li>\n",
        "#@markdown     </ul>\n",
        "#@markdown   </li>\n",
        "#@markdown   <li>\n",
        "#@markdown   Muximum number of clients means all classes contribute in every client\n",
        "#@markdown   </li>\n",
        "\n",
        "#@markdown </ul>\n",
        "\n",
        "\n",
        "#@markdown </br></br><h3>Combination of classes are randomly selected which suits definition of federated learning especially Cross-device federated learning</h3>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVtH-qLIrAeh"
      },
      "source": [
        "# Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmFcWGtXrLS1",
        "outputId": "24110aac-3c9d-4676-ad77-a88ff64f294a",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 50000\n",
            "Size of subset:  [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]\n"
          ]
        }
      ],
      "source": [
        "# @title data splitting\n",
        "\n",
        "set_seed(seed,is_seed_fixed)\n",
        "generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "total_size = len(full_train)\n",
        "train_size = int(train_frac * total_size)\n",
        "val_size   = total_size - train_size\n",
        "\n",
        "train_set, val_set = random_split(full_train, [train_size, val_size], generator=generator)\n",
        "train_indices = torch.tensor(train_set.indices)\n",
        "val_indices = torch.tensor(val_set.indices)\n",
        "\n",
        "train_set = Subset(train_set.dataset, train_indices)\n",
        "val_set = Subset(val_set.dataset, val_set.indices)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=len(train_set), shuffle=False)\n",
        "if val_size > 0:\n",
        "  val_loader  =  DataLoader(val_set, batch_size=len(val_set), shuffle=False)\n",
        "  print(f\"Validation dataset size: {len(val_set)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Train dataset size: {len(train_set)}\")\n",
        "\n",
        "lenghts = [train_size//n_clients] * n_clients\n",
        "\n",
        "for i in range(train_size % n_clients):\n",
        "  lenghts[i] += 1\n",
        "print(\"Size of subset: \", lenghts)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n86IvSfkp9Zv"
      },
      "outputs": [],
      "source": [
        "# @title i.i.d sharing - split data dased on number of clients and with respect of label proportionality\n",
        "set_seed(seed,is_seed_fixed)\n",
        "def iid_sharing(dataset, n_clients):\n",
        "\n",
        "  full_train_indices = dataset.indices\n",
        "  full_train_labels = torch.from_numpy(np.array(dataset.dataset.targets)[full_train_indices]) #collects labels from all dataset\n",
        "  unique_lables = torch.unique(full_train_labels) #Removes dupilication and generates a uniuqe list of labels (classes)\n",
        "  classes_indices = {}\n",
        "\n",
        "\n",
        "  for i in unique_lables:\n",
        "    classes_indices[i] = (full_train_labels == i).nonzero(as_tuple=True)[0] #Collects and save Indices in an array based on classes\n",
        "\n",
        "  for i in classes_indices.keys():\n",
        "    classes_indices[i] = classes_indices[i][torch.randperm(classes_indices[i].shape[0])] #suffels the indices\n",
        "\n",
        "\n",
        "  client_indices = {}\n",
        "\n",
        "\n",
        "\n",
        "  for client in range(n_clients):\n",
        "    if not client_indices.get(client):\n",
        "      client_indices[client] = torch.empty(0, dtype=torch.long)\n",
        "\n",
        "\n",
        "  for label in classes_indices.keys():\n",
        "    class_sample_size = len(classes_indices[label]) // n_clients\n",
        "    for k in range(n_clients):\n",
        "\n",
        "      client_indices[k] = torch.cat((client_indices[k], classes_indices[label][class_sample_size * k : class_sample_size * (k + 1)]), dim=0)\n",
        "\n",
        "  for label in classes_indices.keys():\n",
        "    remainder  = len(classes_indices[label]) % n_clients\n",
        "\n",
        "    for r in range(1,remainder+1):\n",
        "      random_client = random.choice(list(client_indices.keys()))\n",
        "      client_indices[random_client] = torch.cat((client_indices[random_client], classes_indices[label][-r].unsqueeze(0)), dim=0)\n",
        "\n",
        "  full_train_indices_t = torch.as_tensor(full_train_indices, dtype=torch.long)\n",
        "  client_data = {\n",
        "      client_id: Subset(\n",
        "          dataset.dataset,\n",
        "          full_train_indices_t[indices][torch.randperm(len(indices))].tolist()\n",
        "      )\n",
        "      for client_id, indices in client_indices.items()\n",
        "  }\n",
        "\n",
        "\n",
        "  #split actual dataset to multiple subset for clients\n",
        "  # client_data={\n",
        "  #     client_id: Subset(dataset.dataset,indices[torch.randperm(len(indices))])\n",
        "  #     for client_id, indices in client_indices.items()\n",
        "  # }\n",
        "  return client_data\n",
        "\n",
        "# indices_check = []\n",
        "# client_data = iid_sharing(train_set, n_clients)\n",
        "# s = 0\n",
        "# for client_id in client_data.keys():\n",
        "#   indices_check = indices_check + list(client_data[client_id].indices)\n",
        "#   s+= len(client_data[client_id])\n",
        "#   print(f\"Client {client_id} has {len(client_data[client_id])} samples\")\n",
        "# print(s, len(train_set))\n",
        "# del indices_check,client_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UHYGEz82-ZJs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Non i.i.d sharing\n",
        "\n",
        "\n",
        "# @title i.i.d sharing - split data dased on number of clients and with respect of label proportionality\n",
        "set_seed(seed,is_seed_fixed)\n",
        "def noniid_sharing(dataset,Nc , n_clients):\n",
        "\n",
        "  full_train_indices = dataset.indices\n",
        "  full_train_labels = torch.tensor(dataset.dataset.targets)[full_train_indices] #collects labels from all dataset\n",
        "  unique_lables = torch.unique(full_train_labels) #Removes dupilication and generates a uniuqe list of labels (classes)\n",
        "\n",
        "  classes_indices = {}\n",
        "  classes_size = torch.zeros(unique_lables.size()[0])\n",
        "\n",
        "  class_combs = get_class_combinations(unique_lables, Nc, n_clients)\n",
        "\n",
        "  classes_num_partition = torch.zeros(unique_lables.size()[0])\n",
        "\n",
        "  for i in unique_lables:\n",
        "    classes_num_partition[i] = torch.sum(class_combs == i)\n",
        "    classes_indices[i.item()] = torch.nonzero(full_train_labels == i).squeeze() #Collects and save Indices in an array based on classe\n",
        "    classes_size[i] = classes_indices[i.item()].size()[0] #Calculate the number of smaples belonging to each class\n",
        "\n",
        "  for i in classes_indices.keys():\n",
        "    classes_indices[i] = classes_indices[i][torch.randperm(classes_indices[i].shape[0])] #suffels the indices\n",
        "\n",
        "  client_indices = {client: torch.tensor([],dtype=torch.int64) for client in range(n_clients) }\n",
        "  assigned_indices = set()\n",
        "\n",
        "  #For each client we generate a element in client_indices dict to keep track of indices we'll associated with each client\n",
        "\n",
        "  for client in range(n_clients):\n",
        "    for cls in class_combs[client]:\n",
        "      cls = cls.item()\n",
        "\n",
        "      portion  = classes_size[cls] /classes_num_partition[cls]\n",
        "      portion = int(portion) if not portion % 1 else int(portion) + 1\n",
        "      portion = min(portion, classes_indices[cls].size()[0])\n",
        "\n",
        "      class_partition = classes_indices[cls][:portion]\n",
        "\n",
        "      class_partition = [idx for idx in class_partition if idx not in assigned_indices]\n",
        "\n",
        "      assigned_indices.update(class_partition)\n",
        "\n",
        "      class_partition = torch.tensor(class_partition, dtype=torch.int64)\n",
        "\n",
        "      client_indices[client] = torch.cat((client_indices[client], class_partition), dim=0)\n",
        "\n",
        "      classes_indices[cls] = classes_indices[cls][portion:]\n",
        "\n",
        "  client_data={\n",
        "      client_id: Subset(dataset.dataset,indices[torch.randperm(len(indices))])\n",
        "      for client_id, indices in client_indices.items()\n",
        "      if len(indices) > 0\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  return client_data, class_combs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_class_combinations(classes, Nc, n_clients):\n",
        "\n",
        "  if Nc * n_clients < len(classes):\n",
        "    Nc = len(classes) / n_clients\n",
        "    Nc = int(Nc) if not Nc % 1 else int(Nc) + 1\n",
        "\n",
        "    print(f\"Number of classes per clients is lower then minimum. Nc changed to {Nc} (the least possible value)\")\n",
        "\n",
        "  combinations = torch.zeros((n_clients,Nc),dtype= torch.int64)\n",
        "  counter =0\n",
        "  ofset = 0\n",
        "  flag = False\n",
        "\n",
        "  for i in range(n_clients):\n",
        "    if not flag:\n",
        "      end_pointer = (i + 1) * Nc\n",
        "      if end_pointer >= classes.size()[0]:\n",
        "          ofset = (end_pointer - classes.size()[0])\n",
        "          flag = True\n",
        "\n",
        "      combinations[i] = classes[i* Nc - ofset: end_pointer - ofset]\n",
        "\n",
        "    else:\n",
        "\n",
        "      combinations[i]  = torch.randperm(classes.size()[0])[:Nc]\n",
        "\n",
        "  return combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqWviCIKs-eN"
      },
      "source": [
        "# Log System\n",
        "\n",
        "In this section Requerd Data will be stored.<br/><br/>\n",
        "**Archaving this information will make it possible to:**\n",
        "*   Handle Clients\n",
        "*   Manage the models\n",
        "*   Keep track of results of different Backbones\n",
        "*   Compare measurement criteria\n",
        "*   Handel model merging process\n",
        "*   Save path to the models\n",
        "\n",
        "<br/><br/>\n",
        "**These data will be saved in two seperted csv file to :**\n",
        "\n",
        "1.   Store the LOCAL Models  \n",
        "2.   Store the GLOBAL Models resulted by each round\n",
        "\n",
        "<br/><br/>\n",
        "The csv files will be handeled as panda.dataframe and each row in the csv file addresses one of models\n",
        "<br/>\n",
        "\n",
        "**Columns (COMMON):**<br/>\n",
        "1. Backbone model name\n",
        "2. Model name\n",
        "3. Path\n",
        "4. Time of log\n",
        "5. Measurement criteria\n",
        " * loss\n",
        " * Accuracy\n",
        " * ...?\n",
        "6. Size of dataset\n",
        "\n",
        "**Columns (Local Models only):**<br/>\n",
        "7. Client Id\n",
        "8. Classes (Indicate which classes have been covered by each client)(format:\"2,4,63,80,9\" or \"all\" for all the classes)\n",
        "9. Round number\n",
        "10. Duration of training\n",
        "11. Train Test ratio\n",
        "\n",
        "**Columns (Global Models only):**<br/>\n",
        "7. Number of clients\n",
        "7. Number of rounds\n",
        "8. Model Aggregation method\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CasHI07Ps4A8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Functions\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive\n",
        "from uuid import uuid4\n",
        "import os\n",
        "\n",
        "def get_current_time():\n",
        "  now = datetime.now()\n",
        "\n",
        "  formatted_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\") # Format the date and time as a string\n",
        "\n",
        "  return formatted_date_time\n",
        "\n",
        "\n",
        "\n",
        "tic_start_time = None\n",
        "\n",
        "def next_id(log_path):\n",
        "  if os.path.exists(log_path) :\n",
        "    df = pd.read_csv(log_path)\n",
        "    while True:\n",
        "      uuid = str(uuid4())\n",
        "      if uuid not in df[\"model_name\"].values:\n",
        "        return uuid\n",
        "  else:\n",
        "    return str(uuid4())\n",
        "\n",
        "\n",
        "\n",
        "def tic():\n",
        "    global tic_start_time\n",
        "    tic_start_time = time.perf_counter() # start the timer\n",
        "\n",
        "def toc():\n",
        "    if tic_start_time is None:\n",
        "        print(\"Error: You must call tic() before toc()\")\n",
        "        return None\n",
        "    elapsed_time = time.perf_counter() - tic_start_time\n",
        "    return elapsed_time\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l66ikAyqfg4f"
      },
      "source": [
        "# Model and model configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iiwRCHrwfk63"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import defaultdict\n",
        "\n",
        "class DinoClassifier(nn.Module):\n",
        "  def __init__(self, dino_model, num_classes:int=100, device=None):\n",
        "    super(DinoClassifier, self).__init__()\n",
        "    self.backbone = dino_model\n",
        "\n",
        "    #We need to freaze thhe parameters of bakbone first so we can train only on the head layer(output layer)\n",
        "    for param in self.backbone.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    #determine the Device\n",
        "    if device is None:\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.backbone.to(device)\n",
        "\n",
        "    #To detect the output feature dimontion of backbone we run  Dummy forward pass\n",
        "    with torch.no_grad():\n",
        "\n",
        "      dummy_input = torch.randn(1,3,224,224).to(device)\n",
        "      dummy_out = self.backbone(dummy_input)\n",
        "\n",
        "\n",
        "      if isinstance(dummy_out, tuple):\n",
        "        dummy_out = dummy_out[0]\n",
        "      elif isinstance(dummy_out, dict):\n",
        "        dummy_out = dummy_out.get(\"x_norm_clstoken\", next(iter(dummy_out.values())))\n",
        "\n",
        "      #If the output is 3D (B, T, D), we assume first token is the [CLS] token.\n",
        "      if dummy_out.dim() == 3:\n",
        "        dummy_feature = dummy_out[:,0]\n",
        "      else:\n",
        "        dummy_feature = dummy_out\n",
        "      feature_dim = dummy_feature.shape[1]\n",
        "\n",
        "      #Difineing the classification Head\n",
        "      self.head = nn.Linear(feature_dim, num_classes)\n",
        "\n",
        "      #Ensure the head is trainable.\n",
        "      for param in self.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #pass the input through the backbone\n",
        "    features = self.backbone(x)\n",
        "\n",
        "    if isinstance(features, tuple):\n",
        "      features = features[0]\n",
        "    elif isinstance(features, dict):\n",
        "      features = features.get(\"x_norm_clstoken\", next(iter(features.values())))\n",
        "\n",
        "\n",
        "    # If featers are retuened as (B, T, D), use the first token\n",
        "    if features.dim() == 3:\n",
        "      cls_token = features[:,0]\n",
        "    else:\n",
        "      cls_token = features\n",
        "    logits = self.head(cls_token)\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9teqJtq_fG47"
      },
      "source": [
        "# Clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "2ynAlV1-oyhY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Subset\n",
        "import pandas as pd\n",
        "import torch.hub\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader # Import DataLoader\n",
        "\n",
        "set_seed(seed,is_seed_fixed)\n",
        "\n",
        "class Client:\n",
        "\n",
        "\n",
        "  def __init__(self, id, data, n_clients, spliting_method,num_local_steps = 4,GM_rounds=5, target_sparsity=0.9, batch_size = 32, classes=\"all\",  backbone=\"dino_vits16\", path_to_model=None, raw_model=None,do_test=False, spliting_ratio={\"train\":0.8, \"test\":0.2}, path_to_subsets=\"\", path_to_class_combs=\"\"):\n",
        "    self.id = id\n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Corrected cuda() to is_available()\n",
        "    self.data_set = data\n",
        "    self.spliting_method = spliting_method\n",
        "    self.classes = classes\n",
        "\n",
        "    self.backbone = backbone\n",
        "    self.path_to_model = path_to_model\n",
        "    self.model = raw_model\n",
        "    self.load_model()\n",
        "    self.do_test = do_test\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.train_set , self.test_set = self.test_train_split()\n",
        "    self.target_sparsity = target_sparsity\n",
        "    self.GM_rounds = GM_rounds\n",
        "    self.sparsities = self.claculate_sparsity()\n",
        "    self.grad_mask = self.calculate_fisher_mask()\n",
        "    self.n_clients = n_clients\n",
        "\n",
        "\n",
        "    self.spliting_ratio = spliting_ratio\n",
        "\n",
        "    self.num_local_steps = num_local_steps\n",
        "    self.selected_batches = []\n",
        "    self.get_random_batches()\n",
        "    self.duration = 0.0\n",
        "    self.train_loss = None\n",
        "    self.accuracy = None\n",
        "    self.loss = None\n",
        "    self.path_to_subsets = path_to_subsets\n",
        "    self.path_to_class_combs = path_to_class_combs\n",
        "\n",
        "\n",
        "  def test_train_split(self):\n",
        "    if self.do_test:\n",
        "      train_size = int(self.spliting_ratio.get(\"train\") * len(self.data_set))\n",
        "      test_size =  len(self.data_set) - train_size\n",
        "\n",
        "      train_set, test_set = random_split(self.data_set, [ train_size, test_size ])\n",
        "      train_set = DataLoader(train_set, batch_size=self.batch_size, shuffle=True,  num_workers=2)\n",
        "      test_set = DataLoader(test_set, batch_size=self.batch_size, shuffle=False,  num_workers=2)\n",
        "      return train_set, test_set\n",
        "\n",
        "    else:\n",
        "      spliting_ratio={\"train\":1, \"test\":0}\n",
        "      train_set = DataLoader(self.data_set, batch_size=self.batch_size, shuffle=True,  num_workers=2)\n",
        "      return train_set , None\n",
        "\n",
        "  def get_random_batches(self):\n",
        "    total_batches = len(self.train_set)\n",
        "\n",
        "    selected_indices = torch.sort(torch.randperm(total_batches)[:self.num_local_steps])[0]\n",
        "\n",
        "    selected_indices = list(set(selected_indices.tolist()))\n",
        "    random.shuffle(selected_indices)\n",
        "    self.selected_batches = []\n",
        "\n",
        "    for i, batch in enumerate(self.train_set):\n",
        "      if i in selected_indices:\n",
        "\n",
        "        self.selected_batches.append(batch)\n",
        "    # print(\"Total number of batches: \",total_batches, \" - Number of selected batches: \", len(self.selected_batches), \"selected batches: \",selected_indices )\n",
        "\n",
        "\n",
        "  def load_model(self):\n",
        "    if self.model is None:\n",
        "      dino_model = torch.hub.load('facebookresearch/dino:main', self.backbone)\n",
        "      self.model = DinoClassifier(dino_model=dino_model, num_classes=100, device=self.device)\n",
        "    if self.path_to_model:\n",
        "      state_dict = torch.load(self.path_to_model)\n",
        "      self.model.head.load_state_dict(state_dict)\n",
        "      # print(\"Model loaded successfully \")\n",
        "\n",
        "    self.model.to(self.device)\n",
        "\n",
        "  def gradient_mask(self):\n",
        "\n",
        "\n",
        "    for name, param in self.model.head.named_parameters():\n",
        "        if name in self.grad_mask and param.grad is not None:\n",
        "\n",
        "          param.grad *= self.grad_mask[name].to(param.grad.device)\n",
        "\n",
        "\n",
        "\n",
        "  def calculate_fisher_mask(self, n=5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    head_params = [p for p in self.model.head.parameters()]\n",
        "    param_ids = [id(p) for p in head_params]\n",
        "\n",
        "\n",
        "    fisher_scores = {id_p:torch.zeros_like(p, device=self.device) for id_p,p in  zip(param_ids, head_params)}\n",
        "    last_mask = {id_p:torch.ones_like(p, device=self.device) for id_p,p in  zip(param_ids, head_params)}\n",
        "\n",
        "\n",
        "\n",
        "    self.model.eval()\n",
        "\n",
        "    for i in range(n):\n",
        "\n",
        "      for v in fisher_scores.values():\n",
        "        v.zero_()\n",
        "\n",
        "      for images, labels in self.train_set:\n",
        "        images, labels = images.to(self.device), labels.to(self.device)\n",
        "        outputs = self.model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        grads = torch.autograd.grad(\n",
        "            loss,\n",
        "            head_params,\n",
        "            create_graph=False,\n",
        "            retain_graph=False\n",
        "        )\n",
        "\n",
        "        for p, g in zip(head_params,grads):\n",
        "          pid = id(p)\n",
        "          fisher_scores[pid] += g.detach().pow(2) * last_mask[pid]\n",
        "\n",
        "      all_scores = torch.cat([\n",
        "           fisher_scores[id(p)].mul(last_mask[id(p)]).reshape(-1)\n",
        "          for p in  head_params\n",
        "          ])\n",
        "\n",
        "      non_zero  = all_scores[all_scores != 0]\n",
        "\n",
        "      if non_zero.numel() == 0:\n",
        "        new_mask = {id(p):torch.zeros_like(p,device=self.device) for p in head_params }\n",
        "        last_mask = new_mask\n",
        "        continue\n",
        "\n",
        "      total_nz = non_zero.numel()\n",
        "      keep = int( (1 - self.sparsities[i])* total_nz)\n",
        "      keep = min(keep, total_nz)\n",
        "\n",
        "      if keep == 0:\n",
        "        threshold = non_zero.max() + 1\n",
        "      elif keep == total_nz:\n",
        "        threshold = non_zero.min() - 1\n",
        "\n",
        "      else:\n",
        "        kth_smallest = total_nz - keep + 1\n",
        "        threshold, _ = torch.kthvalue(non_zero, k= kth_smallest)\n",
        "\n",
        "      new_mask = {}\n",
        "\n",
        "      for p in head_params:\n",
        "        pid = id(p)\n",
        "        masked_scores = fisher_scores[pid] * last_mask[pid]\n",
        "        current_mask = (masked_scores >= threshold).float() * last_mask[pid]\n",
        "        new_mask[pid]  = current_mask\n",
        "        last_mask[pid] = current_mask\n",
        "\n",
        "    return new_mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def claculate_sparsity(self, a= 0.4, decimals= 3):\n",
        "    n =  self.GM_rounds\n",
        "    S = self.target_sparsity\n",
        "    St = []\n",
        "    Ct = [ S * (  (1-math.exp(-a*t)) / (1-math.exp(-a*n))  ) for t in  range(1,n+1) ]\n",
        "    for t in  range(n):\n",
        "      ct0 = 0 if t==0 else Ct[t-1]\n",
        "      St.append( round(1- (1-Ct[t])/(1-ct0), decimals ) )\n",
        "    return St\n",
        "\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def SGDM(self, buffer,weight_decay=0.0,lr=1e-3,momentum=0.9,damping=0.0, nesterov=False, max_=False):\n",
        "    for param in self.model.head.parameters():\n",
        "      if param.grad is None:\n",
        "        continue\n",
        "      grad = param.grad\n",
        "\n",
        "      if weight_decay != 0:\n",
        "        grad = grad.add(param, alpha=weight_decay)\n",
        "\n",
        "      pid = id(param)\n",
        "      buf = buffer.get(pid)\n",
        "      if buf is None:\n",
        "        buf = torch.zeros_like(param)\n",
        "        buffer[pid] = buf\n",
        "\n",
        "\n",
        "      if momentum != 0 :\n",
        "        buf.mul_(momentum).add_(grad, alpha=(1 - damping))\n",
        "        update = grad.add(buf, alpha= momentum) if nesterov else buf\n",
        "\n",
        "      else:\n",
        "\n",
        "        update = grad\n",
        "\n",
        "      gm = self.grad_mask\n",
        "      mask = gm.get(pid)\n",
        "\n",
        "      if mask is None:\n",
        "        mask = torch.ones_like(update)\n",
        "      else:\n",
        "        mask = mask.to(device=update.device, dtype=update.dtype)\n",
        "        if mask.numel() == 1:\n",
        "          mask = mask.expand_as(update)\n",
        "        elif mask.shape != update.shape:\n",
        "\n",
        "          mask = mask.expand_as(update)\n",
        "\n",
        "      update = update * mask\n",
        "\n",
        "      param.add_(update, alpha=(lr if max_ else -lr))\n",
        "\n",
        "      buffer[pid] = buf\n",
        "    return buffer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def SGDM_train(self):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    tic()\n",
        "\n",
        "\n",
        "\n",
        "    for p in self.model.backbone.parameters():\n",
        "      p.requires_grad = False\n",
        "    self.model.backbone.eval()\n",
        "\n",
        "    for p in self.model.head.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    self.model.train()\n",
        "\n",
        "    buffer = {}\n",
        "    running_loss = 0.0\n",
        "    loss_lst = {}\n",
        "\n",
        "\n",
        "    for step_num in range(len(self.selected_batches)):\n",
        "      images, labels = self.selected_batches[step_num]\n",
        "      images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "      self.model.zero_grad(set_to_none=True)\n",
        "      outputs = self.model(images)\n",
        "      loss = criterion(outputs, labels.long())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      buffer = self.SGDM(buffer=buffer, momentum=0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      # loc_stp_loss = running_loss / len(self.train_set)\n",
        "      avg_loss = running_loss / (step_num + 1)\n",
        "      loss_lst[step_num] = f\"{avg_loss:.4f} \"\n",
        "\n",
        "      # print(f\"client: {self.id}- local step number: {step_num} - step loss: {avg_loss:.4f} \" )\n",
        "    print(f\"client:{self.id}_  losses\",loss_lst)\n",
        "\n",
        "    self.duration = toc()\n",
        "    self.train_loss = running_loss / len(self.selected_batches)\n",
        "    # self.train_loss = running_loss / max(1, len(self.selected_batches))\n",
        "\n",
        "  def train_default(self):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(self.model.head.parameters(), lr=1e-3, momentum=0.9)\n",
        "    tic()\n",
        "    self.calculate_fisher_mask()\n",
        "\n",
        "\n",
        "    for p in self.model.backbone.parameters():\n",
        "      p.requires_grad = False\n",
        "    self.model.backbone.eval()\n",
        "\n",
        "    for p in self.model.head.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    self.model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    loss_lst = {}\n",
        "    for step_num in range(len(self.selected_batches)):\n",
        "\n",
        "\n",
        "      images, labels = self.selected_batches[step_num]\n",
        "      images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "      outputs = self.model(images)\n",
        "      loss = criterion(outputs, labels.long())\n",
        "      loss.backward()\n",
        "\n",
        "\n",
        "      for p in self.model.head.parameters():\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            m = self.grad_mask.get(id(p))\n",
        "            if m is not None:\n",
        "                p.grad.mul_(m.to(p.grad.device, dtype=p.grad.dtype))\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # loc_stp_loss = running_loss / len(self.train_set)\n",
        "      avg_loss = running_loss / (step_num + 1)\n",
        "      loss_lst[step_num] = f\"{avg_loss:.4f} \"\n",
        "\n",
        "    print(f\"client:{self.id}_  losses\",loss_lst)\n",
        "    self.duration = toc()\n",
        "    self.train_loss = running_loss / len(self.selected_batches)\n",
        "    # self.train_loss = running_loss / max(1, len(self.selected_batches))\n",
        "\n",
        "  def evaluate(self):\n",
        "    if self.do_test:\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      self.model.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      test_loss = 0\n",
        "      with torch.no_grad():\n",
        "        for index, (images, labels) in enumerate(self.train_set):\n",
        "          images, labels = images.to(self.device), labels.to(self.device)\n",
        "          outputs = self.model(images)\n",
        "\n",
        "          _, prediction = torch.max(outputs.data,1)\n",
        "          loss = criterion(outputs, labels)\n",
        "          test_loss += loss.item() * labels.size(0)\n",
        "\n",
        "\n",
        "          total += labels.size(0)\n",
        "\n",
        "          correct += (prediction == labels).sum().item()\n",
        "      self.accuracy = 100 * correct / total\n",
        "      self.loss = test_loss / total\n",
        "    else:\n",
        "      self.accuracy = None\n",
        "      self.loss = None\n",
        "\n",
        "  def confirm_save(self,path):\n",
        "      torch.save(self.model.head.state_dict(),  path )\n",
        "\n",
        "  def create_log(self, model_name, path, round_number):\n",
        "\n",
        "    log_dict= {\n",
        "        \"client_id\":[self.id],\n",
        "        \"backbone\":[self.backbone],\n",
        "        \"model_name\":[model_name],\n",
        "        \"initial_model_name\":[initial_model_name],\n",
        "        \"path\": [path],\n",
        "        \"num_of_clients\":[self.n_clients],\n",
        "        \"Measurement_criteria\":[\"accuracy,loss,train_loss\" if self.do_test else \"train_loss\"],\n",
        "        \"accuracy\":[self.accuracy],\n",
        "        \"loss\":[self.loss],\n",
        "        \"train_loss\":[self.train_loss],\n",
        "        \"splitting_method\":[self.spliting_method],\n",
        "        \"sparsity\":[self.target_sparsity],\n",
        "        \"sparsities\":[self.sparsities ] ,\n",
        "        \"GM_rounds\":[self.GM_rounds],\n",
        "        \"num_local_steps\":[self.num_local_steps],\n",
        "        \"size_of_dataset\": [len(self.data_set.dataset)],\n",
        "        \"client_train_size\": [len(self.train_set.dataset)],\n",
        "        \"client_test_size\": [len(self.test_set.dataset) if self.do_test else 0],\n",
        "        \"train_test_ratio\":[self.spliting_ratio],\n",
        "        \"classes\":[self.classes],\n",
        "        \"round_number\":[round_number],\n",
        "        \"duration\":[self.duration],\n",
        "        \"time\": [get_current_time()],\n",
        "        \"path_to_subsets\":[self.path_to_subsets],\n",
        "        \"path_to_class_combs\":[self.path_to_class_combs]\n",
        "\n",
        "    }\n",
        "    final_log = pd.DataFrame(log_dict)\n",
        "    final_log = final_log[['client_id', 'backbone', 'model_name', 'initial_model_name', 'path','num_of_clients','train_loss', 'splitting_method', 'sparsity', 'sparsities', 'GM_rounds','size_of_dataset', 'client_train_size', 'client_test_size', 'train_test_ratio', 'classes', 'round_number','num_local_steps', 'duration', 'time','path_to_subsets', 'path_to_class_combs']]\n",
        "\n",
        "    return final_log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# temp_clients_log = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\")\n",
        "# temp_clients_log[\"backbone\"]= [\"dino_vits16\"]*len(temp_clients_log)\n",
        "# temp_clients_log[\"path_to_subsets\"]= [\"/content/drive/MyDrive/MLDL_FederatedLearning/client_subsets/client_data_iid_100clients_5455920f-4657-43ce-8e9e-accab67d8bfd.pth\"]*len(temp_clients_log)\n",
        "# temp_clients_log[\"path_to_class_combs\"]= [None]*len(temp_clients_log)\n",
        "# temp_clients_log[\"num_local_steps\"] = [5]*len(temp_clients_log)\n",
        "# temp_clients_log = temp_clients_log[['client_id', 'backbone', 'model_name', 'initial_model_name', 'path',\n",
        "#        'num_of_clients',\n",
        "#        'train_loss', 'splitting_method', 'sparsity', 'sparsities', 'GM_rounds',\n",
        "#        'size_of_dataset', 'client_train_size', 'client_test_size',\n",
        "#        'train_test_ratio', 'classes', 'round_number','num_local_steps', 'duration', 'time',\n",
        "#        'path_to_subsets', 'path_to_class_combs']]\n",
        "# temp_clients_log.to_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\", index=False)\n",
        "\n",
        "# temp_clients_log[-10:].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "CzwFOvX2fh5h",
        "outputId": "312487a1-6800-44ab-aa44-90b27e550fce"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      client_id     backbone                            model_name  \\\n",
              "1490         21  dino_vits16  ec2441b6-1b43-4429-85ae-314956168776   \n",
              "1491         16  dino_vits16  140f1fd1-f391-47ec-8153-a0ceddb7c8d0   \n",
              "1492         33  dino_vits16  9463e048-a8cb-4717-a31c-b144c9d12257   \n",
              "1493         51  dino_vits16  fb9ca6c5-0a96-4269-a8dc-e5692c54d3ad   \n",
              "1494         73  dino_vits16  ac43a559-3450-496c-a612-2af230146325   \n",
              "\n",
              "                        initial_model_name  \\\n",
              "1490  5db68ebd-7c95-41fb-b1b4-054d9c386688   \n",
              "1491  5db68ebd-7c95-41fb-b1b4-054d9c386688   \n",
              "1492  5db68ebd-7c95-41fb-b1b4-054d9c386688   \n",
              "1493  5db68ebd-7c95-41fb-b1b4-054d9c386688   \n",
              "1494  5db68ebd-7c95-41fb-b1b4-054d9c386688   \n",
              "\n",
              "                                                   path  num_of_clients  \\\n",
              "1490  /content/drive/MyDrive/MLDL_FederatedLearning/...             100   \n",
              "1491  /content/drive/MyDrive/MLDL_FederatedLearning/...             100   \n",
              "1492  /content/drive/MyDrive/MLDL_FederatedLearning/...             100   \n",
              "1493  /content/drive/MyDrive/MLDL_FederatedLearning/...             100   \n",
              "1494  /content/drive/MyDrive/MLDL_FederatedLearning/...             100   \n",
              "\n",
              "      train_loss splitting_method  sparsity  \\\n",
              "1490    3.073904   i.i.d. sharing       0.9   \n",
              "1491    2.993020   i.i.d. sharing       0.9   \n",
              "1492    2.822621   i.i.d. sharing       0.9   \n",
              "1493    2.900411   i.i.d. sharing       0.9   \n",
              "1494    2.812206   i.i.d. sharing       0.9   \n",
              "\n",
              "                                             sparsities  ...  \\\n",
              "1490  [0.3431526148986126, 0.35019105173202925, 0.36...  ...   \n",
              "1491  [0.3431526148986126, 0.35019105173202925, 0.36...  ...   \n",
              "1492  [0.3431526148986126, 0.35019105173202925, 0.36...  ...   \n",
              "1493  [0.3431526148986126, 0.35019105173202925, 0.36...  ...   \n",
              "1494  [0.3431526148986126, 0.35019105173202925, 0.36...  ...   \n",
              "\n",
              "      client_train_size  client_test_size             train_test_ratio  \\\n",
              "1490                500                 0  {'train': 0.8, 'test': 0.2}   \n",
              "1491                500                 0  {'train': 0.8, 'test': 0.2}   \n",
              "1492                500                 0  {'train': 0.8, 'test': 0.2}   \n",
              "1493                500                 0  {'train': 0.8, 'test': 0.2}   \n",
              "1494                500                 0  {'train': 0.8, 'test': 0.2}   \n",
              "\n",
              "      classes round_number num_local_steps  duration                 time  \\\n",
              "1490      all          150               5  0.507474  2025-09-04 14:38:27   \n",
              "1491      all          150               5  0.556099  2025-09-04 14:38:39   \n",
              "1492      all          150               5  0.549843  2025-09-04 14:38:51   \n",
              "1493      all          150               5  0.553275  2025-09-04 14:39:04   \n",
              "1494      all          150               5  0.551437  2025-09-04 14:39:16   \n",
              "\n",
              "                                        path_to_subsets path_to_class_combs  \n",
              "1490  /content/drive/MyDrive/MLDL_FederatedLearning/...                None  \n",
              "1491  /content/drive/MyDrive/MLDL_FederatedLearning/...                None  \n",
              "1492  /content/drive/MyDrive/MLDL_FederatedLearning/...                None  \n",
              "1493  /content/drive/MyDrive/MLDL_FederatedLearning/...                None  \n",
              "1494  /content/drive/MyDrive/MLDL_FederatedLearning/...                None  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d992b46f-d4b0-455d-a95f-2f6fc9b7158a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>backbone</th>\n",
              "      <th>model_name</th>\n",
              "      <th>initial_model_name</th>\n",
              "      <th>path</th>\n",
              "      <th>num_of_clients</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>splitting_method</th>\n",
              "      <th>sparsity</th>\n",
              "      <th>sparsities</th>\n",
              "      <th>...</th>\n",
              "      <th>client_train_size</th>\n",
              "      <th>client_test_size</th>\n",
              "      <th>train_test_ratio</th>\n",
              "      <th>classes</th>\n",
              "      <th>round_number</th>\n",
              "      <th>num_local_steps</th>\n",
              "      <th>duration</th>\n",
              "      <th>time</th>\n",
              "      <th>path_to_subsets</th>\n",
              "      <th>path_to_class_combs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1490</th>\n",
              "      <td>21</td>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>ec2441b6-1b43-4429-85ae-314956168776</td>\n",
              "      <td>5db68ebd-7c95-41fb-b1b4-054d9c386688</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>100</td>\n",
              "      <td>3.073904</td>\n",
              "      <td>i.i.d. sharing</td>\n",
              "      <td>0.9</td>\n",
              "      <td>[0.3431526148986126, 0.35019105173202925, 0.36...</td>\n",
              "      <td>...</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>{'train': 0.8, 'test': 0.2}</td>\n",
              "      <td>all</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>0.507474</td>\n",
              "      <td>2025-09-04 14:38:27</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491</th>\n",
              "      <td>16</td>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>140f1fd1-f391-47ec-8153-a0ceddb7c8d0</td>\n",
              "      <td>5db68ebd-7c95-41fb-b1b4-054d9c386688</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>100</td>\n",
              "      <td>2.993020</td>\n",
              "      <td>i.i.d. sharing</td>\n",
              "      <td>0.9</td>\n",
              "      <td>[0.3431526148986126, 0.35019105173202925, 0.36...</td>\n",
              "      <td>...</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>{'train': 0.8, 'test': 0.2}</td>\n",
              "      <td>all</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>0.556099</td>\n",
              "      <td>2025-09-04 14:38:39</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492</th>\n",
              "      <td>33</td>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>9463e048-a8cb-4717-a31c-b144c9d12257</td>\n",
              "      <td>5db68ebd-7c95-41fb-b1b4-054d9c386688</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>100</td>\n",
              "      <td>2.822621</td>\n",
              "      <td>i.i.d. sharing</td>\n",
              "      <td>0.9</td>\n",
              "      <td>[0.3431526148986126, 0.35019105173202925, 0.36...</td>\n",
              "      <td>...</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>{'train': 0.8, 'test': 0.2}</td>\n",
              "      <td>all</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>0.549843</td>\n",
              "      <td>2025-09-04 14:38:51</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>51</td>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>fb9ca6c5-0a96-4269-a8dc-e5692c54d3ad</td>\n",
              "      <td>5db68ebd-7c95-41fb-b1b4-054d9c386688</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>100</td>\n",
              "      <td>2.900411</td>\n",
              "      <td>i.i.d. sharing</td>\n",
              "      <td>0.9</td>\n",
              "      <td>[0.3431526148986126, 0.35019105173202925, 0.36...</td>\n",
              "      <td>...</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>{'train': 0.8, 'test': 0.2}</td>\n",
              "      <td>all</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>0.553275</td>\n",
              "      <td>2025-09-04 14:39:04</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>73</td>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>ac43a559-3450-496c-a612-2af230146325</td>\n",
              "      <td>5db68ebd-7c95-41fb-b1b4-054d9c386688</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>100</td>\n",
              "      <td>2.812206</td>\n",
              "      <td>i.i.d. sharing</td>\n",
              "      <td>0.9</td>\n",
              "      <td>[0.3431526148986126, 0.35019105173202925, 0.36...</td>\n",
              "      <td>...</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>{'train': 0.8, 'test': 0.2}</td>\n",
              "      <td>all</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>0.551437</td>\n",
              "      <td>2025-09-04 14:39:16</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d992b46f-d4b0-455d-a95f-2f6fc9b7158a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d992b46f-d4b0-455d-a95f-2f6fc9b7158a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d992b46f-d4b0-455d-a95f-2f6fc9b7158a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6e7fd3f4-2ef3-41cb-be6e-ac65a34537ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e7fd3f4-2ef3-41cb-be6e-ac65a34537ed')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6e7fd3f4-2ef3-41cb-be6e-ac65a34537ed button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "NM8XLj4WmwLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>❗ Important Notice ❗</h1>**\n",
        "\n",
        "**Regarding `save_data`:**\n",
        "Please be aware that checking the `save_data` option will generate a **new data subset** and a **new initial model** based on your specified parameters.\n",
        "\n",
        "**⚠️ Crucial: Using Existing Models with New Data/Parameters ⚠️**\n",
        "If you intend to use an *existing model* but wish to apply it to a *different data subset*, use a *different data splitting method*, or make *any other changes to the data or algorithm*, you **MUST** assign a **new and unique model name**.\n",
        "\n",
        "**Why is this critical?**\n",
        "Failing to use a unique model name will make it impossible to differentiate between models for each client when filtering. This will lead to inaccurate results from the client aggregation function on the server."
      ],
      "metadata": {
        "id": "aw0_IYcv1m7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "save_data = True #@param{\"type\":\"boolean\"}\n",
        "\n",
        "if save_data:\n",
        "  method = \"iid\" if spliting_method == \"i.i.d. sharing\" else \"noniid\"\n",
        "  if spliting_method == \"i.i.d. sharing\":\n",
        "    path_to_subsets = f\"/content/drive/MyDrive/MLDL_FederatedLearning/client_subsets/client_data_{method}_{str(n_clients)}clients_{str(uuid4())}.pth\"\n",
        "    path_to_class_combs = None\n",
        "    client_data = iid_sharing(train_set, n_clients)\n",
        "    class_combs = \"all\"\n",
        "    print(spliting_method)\n",
        "  else:\n",
        "    client_data, class_combs = noniid_sharing(train_set,Nc=Nc, n_clients=n_clients)\n",
        "    path_to_class_combs = f\"/content/drive/MyDrive/MLDL_FederatedLearning/client_subsets/class_combs_{method}_{str(n_clients)}clients_{str(uuid4())}.pth\"\n",
        "    print(spliting_method)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  dino_model = torch.hub.load('facebookresearch/dino:main', backbone)\n",
        "  initial_model = DinoClassifier(dino_model=dino_model, num_classes=100, device=device)\n",
        "  initial_model_name = next_id(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "  initial_model_path = \"/content/drive/MyDrive/MLDL_FederatedLearning/models/global/\" + initial_model_name + \".pth\"\n",
        "  initial_model_round_num = 0\n",
        "  initial_model_log = {\n",
        "    \"backbone\": [backbone],\n",
        "    \"model_name\": [initial_model_name],\n",
        "    \"num_of_clients\": [n_clients],\n",
        "    \"path\": [initial_model_path],\n",
        "    \"Measurement_criteria\": [None],\n",
        "    \"prev_global_model_name\":[None],\n",
        "    \"accuracy\": [None],\n",
        "    \"loss\": [None],\n",
        "    \"splitting_method\": [spliting_method],\n",
        "    \"size_of_dataset\": [len(train_dataset)],\n",
        "    \"train_test_ratio\": [None],\n",
        "    \"classes\": [None],\n",
        "    \"round_number\": [0],\n",
        "    \"time\": [get_current_time()],\n",
        "    \"path_to_subsets\": [path_to_subsets],\n",
        "    \"path_to_class_combs\": [path_to_class_combs],\n",
        "    \"num_of_participants\": [None]\n",
        "}\n",
        "  initial_model_log[\"aggregation_method\"] =[ np.nan]\n",
        "  initial_model_log[\"contributors\"] =[ np.nan]\n",
        "  initial_model_log[\"momentum_vector_path\"] = [np.nan]\n",
        "\n",
        "\n",
        "  initial_model_log = pd.DataFrame(initial_model_log)\n",
        "  initial_model_log = initial_model_log[['backbone',\n",
        "                'num_of_clients',\n",
        "                'splitting_method',\n",
        "                'aggregation_method',\n",
        "                'Measurement_criteria',\n",
        "                'accuracy',\n",
        "                'loss',\n",
        "                'size_of_dataset',\n",
        "                'train_test_ratio',\n",
        "                'classes',\n",
        "                'round_number',\n",
        "                'num_of_participants',\n",
        "                'model_name',\n",
        "                'prev_global_model_name',\n",
        "                \"contributors\",\n",
        "                'path',\n",
        "                \"momentum_vector_path\",\n",
        "                'path_to_subsets',\n",
        "                'path_to_class_combs',\n",
        "                'time'\n",
        "                ]]\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\"):\n",
        "    initial_model_log.to_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\", index=False)\n",
        "  else:\n",
        "    initial_model_log.to_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\", mode='a', header=False, index=False)\n",
        "    print(\"New CSV file\")\n",
        "  torch.save(initial_model.head.state_dict(), initial_model_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  torch.save(client_data, path_to_subsets)\n",
        "  if method== \"noniid\":\n",
        "    torch.save(class_combs, path_to_class_combs)\n",
        "\n",
        "\n",
        "  initial_model_log.head()\n"
      ],
      "metadata": {
        "id": "FSnlxpSszYyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b33d6d-83a3-41f8-b6b9-19b69cf4cefd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i.i.d. sharing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New CSV file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_model_log.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "wcEkISLFe3P3",
        "outputId": "a25b6a55-0c65-4d06-b584-d30fa61d6ae0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      backbone  num_of_clients splitting_method  aggregation_method  \\\n",
              "0  dino_vits16             100   i.i.d. sharing                 NaN   \n",
              "\n",
              "  Measurement_criteria accuracy  loss  size_of_dataset train_test_ratio  \\\n",
              "0                 None     None  None            50000             None   \n",
              "\n",
              "  classes  round_number num_of_participants  \\\n",
              "0    None             0                None   \n",
              "\n",
              "                             model_name prev_global_model_name  contributors  \\\n",
              "0  f142f936-1ed1-4dfb-b0b2-3f99aff46a89                   None           NaN   \n",
              "\n",
              "                                                path  momentum_vector_path  \\\n",
              "0  /content/drive/MyDrive/MLDL_FederatedLearning/...                   NaN   \n",
              "\n",
              "                                     path_to_subsets path_to_class_combs  \\\n",
              "0  /content/drive/MyDrive/MLDL_FederatedLearning/...                None   \n",
              "\n",
              "                  time  \n",
              "0  2025-09-05 10:42:16  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-002cef9f-463e-402c-9967-d2c0351c755b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>backbone</th>\n",
              "      <th>num_of_clients</th>\n",
              "      <th>splitting_method</th>\n",
              "      <th>aggregation_method</th>\n",
              "      <th>Measurement_criteria</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>size_of_dataset</th>\n",
              "      <th>train_test_ratio</th>\n",
              "      <th>classes</th>\n",
              "      <th>round_number</th>\n",
              "      <th>num_of_participants</th>\n",
              "      <th>model_name</th>\n",
              "      <th>prev_global_model_name</th>\n",
              "      <th>contributors</th>\n",
              "      <th>path</th>\n",
              "      <th>momentum_vector_path</th>\n",
              "      <th>path_to_subsets</th>\n",
              "      <th>path_to_class_combs</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>100</td>\n",
              "      <td>i.i.d. sharing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>50000</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>f142f936-1ed1-4dfb-b0b2-3f99aff46a89</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>None</td>\n",
              "      <td>2025-09-05 10:42:16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-002cef9f-463e-402c-9967-d2c0351c755b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-002cef9f-463e-402c-9967-d2c0351c755b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-002cef9f-463e-402c-9967-d2c0351c755b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "initial_model_log",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lastgen_model_name(seed_model_name):\n",
        "  while True:\n",
        "    global_log_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "    prev_models_names = global_log_df[\"prev_global_model_name\"].values\n",
        "\n",
        "    if seed_model_name in prev_models_names:\n",
        "      log_buffer = global_log_df[global_log_df[\"prev_global_model_name\"] == seed_model_name ]\n",
        "      seed_model_name = log_buffer[\"model_name\"].values[0]\n",
        "\n",
        "    else:\n",
        "     return seed_model_name"
      ],
      "metadata": {
        "id": "PPcQAMkbGyGb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set clients parameters\n",
        "\n",
        "local_steps = 4 #@param\n",
        "sparcity = 0.5 #@param\n",
        "fisher_information_matrix_colibration_rounds = 5 #@param\n"
      ],
      "metadata": {
        "id": "eXR2b1K7bn2A"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RmcRGW2lVdE8"
      },
      "outputs": [],
      "source": [
        "# @title Client round\n",
        "set_seed(seed,is_seed_fixed)\n",
        "\n",
        "def clients_round(n_clients,initial_model_name,selection_percentage,spliting_method,client_data,raw_model):\n",
        "  initial_model_name= get_lastgen_model_name(seed_model_name=initial_model_name)\n",
        "  global_log_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "  selected_clients = get_random_clients(n_clients,initial_model_name,selection_percentage)\n",
        "\n",
        "  log_buffer = global_log_df[global_log_df[\"model_name\"] == initial_model_name]\n",
        "  r = log_buffer[\"round_number\"].values[0]\n",
        "  path_to_global_model = log_buffer[\"path\"].values[0]\n",
        "  path_to_subsets = log_buffer[\"path_to_subsets\"].values[0]\n",
        "  path_to_class_combs = log_buffer[\"path_to_class_combs\"].values[0]\n",
        "\n",
        "  if not spliting_method == \"i.i.d. sharing\":\n",
        "    path_to_class_combs = \" \"\n",
        "\n",
        "  log_file = \"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\"\n",
        "\n",
        "\n",
        "  dino_model = torch.hub.load('facebookresearch/dino:main', backbone)\n",
        "  initial_model = DinoClassifier(dino_model=dino_model, num_classes=100, device=device)\n",
        "\n",
        "  for client_num in selected_clients:\n",
        "    if os.path.exists(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\"):\n",
        "      all_clients_df = pd.read_csv(log_file)\n",
        "      filtered_clients_df = all_clients_df[all_clients_df[\"initial_model_name\"] == initial_model_name]\n",
        "      print( f\"{np.where(selected_clients == client_num)[0] +1 }/{len(selected_clients)} \",\"#\"*100)\n",
        "      if client_num in filtered_clients_df[\"client_id\"].values:\n",
        "        print(f\"Client {client_num} is already trained\")\n",
        "        continue\n",
        "\n",
        "    client = Client(id=client_num,\n",
        "                  data=client_data[client_num] ,\n",
        "                  spliting_method=spliting_method,\n",
        "                  classes=\"all\",\n",
        "                  target_sparsity= sparcity,\n",
        "                  GM_rounds=   fisher_information_matrix_colibration_rounds,\n",
        "                  num_local_steps= local_steps,\n",
        "                  n_clients=n_clients,\n",
        "                  raw_model = copy.deepcopy(raw_model),\n",
        "                  path_to_model = path_to_global_model ,\n",
        "                  path_to_subsets=path_to_subsets,\n",
        "                  path_to_class_combs=path_to_class_combs\n",
        "                  )\n",
        "\n",
        "\n",
        "    client.SGDM_train()\n",
        "    # client.train_default()\n",
        "    client.evaluate()\n",
        "    # Use the save_client method from the Client class\n",
        "    log = client.create_log(\n",
        "        model_name=next_id(log_file), # Generate a new model name\n",
        "        path=f\"/content/drive/MyDrive/MLDL_FederatedLearning/models/clients/{next_id(log_file)}.pth\", # Generate a new path\n",
        "        round_number=initial_model_round_num + 1\n",
        "        )\n",
        "    client.confirm_save(log['path'][0]) # Save the model\n",
        "\n",
        "    if not os.path.exists(log_file):\n",
        "      log.to_csv(log_file, index=False)\n",
        "\n",
        "      print(\"new csv file \")\n",
        "      print(f\"name: {log['model_name'][0]} \")\n",
        "      print(f\"path: {log['path'][0]} \")\n",
        "      print(f\"Logged client {client_num} to {log_file}\")\n",
        "\n",
        "    else: # HERE\n",
        "    # Create a new CSV file IF path doesn't exist\n",
        "      # This check is no longer necessary as we generate a new id and path every time\n",
        "      path_check = pd.read_csv(log_file)['model_name'].values # model_name\n",
        "\n",
        "      # if log['model_name'][0] not in path_check:\n",
        "      client.confirm_save(log['path'][0])\n",
        "      log.to_csv(log_file, mode='a', header=False, index=False)\n",
        "      # print(f\"name: {log['model_name'][0]} \")\n",
        "      # print(f\"path: {log['path'][0]} \")\n",
        "      # print(f\"Logged client {client_num} to {log_file}\")\n",
        "      # else :\n",
        "      #   print(\"Existing Log\")\n",
        "    del client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Random clients selection\n",
        "\n",
        "\n",
        "\n",
        "selection_percentage = 10 #@param {\"type\":\"integer\"}\n",
        "\n",
        "def get_random_clients(n_clients, initial_model_name, selection_percentage=10):\n",
        "  global_log = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "  filter = (global_log[\"model_name\"] == initial_model_name)\n",
        "  filtered_models = global_log[filter]\n",
        "\n",
        "  r_num =  filtered_models[\"round_number\"].values[0]\n",
        "\n",
        "\n",
        "  set_seed(int(r_num),is_seed_fixed)\n",
        "  if os.path.exists(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\"):\n",
        "    clients_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\")\n",
        "    clients_df = clients_df[clients_df['initial_model_name']== initial_model_name]\n",
        "    selected_clients = clients_df['client_id'].values\n",
        "  else:\n",
        "    selected_clients = np.array([], dtype=np.int16)\n",
        "  while len(selected_clients) < (selection_percentage / 100 ) * n_clients:\n",
        "    rand_int = torch.randint(0,n_clients,(1,))[0].item()\n",
        "    if rand_int not in selected_clients:\n",
        "      selected_clients = np.append(selected_clients,rand_int)\n",
        "\n",
        "  return selected_clients\n",
        "\n",
        "# selected_clients = get_random_clients(n_clients,initial_model_name,selection_percentage)\n",
        "# print(selected_clients)"
      ],
      "metadata": {
        "id": "T6FBeYb1bWNp",
        "cellView": "form"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Collect clients\n",
        "\n",
        "def get_clients(initial_model_name):\n",
        "  clients_data = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\")\n",
        "\n",
        "  filter =  clients_data['initial_model_name']== initial_model_name\n",
        "  filtered_clients_data = clients_data[filter] # Using filter to collect clients with specified initial model\n",
        "\n",
        "  print(\"Number of all trained clients:\", len(clients_data))\n",
        "  print(\"Number of clients after filtering:\", len(filtered_clients_data))\n",
        "  return filtered_clients_data\n"
      ],
      "metadata": {
        "id": "hDnfcbCpGex5",
        "cellView": "form"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# server circle"
      ],
      "metadata": {
        "id": "0MlSF8gk7Ir3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title generation of new model's name\n",
        "def global_model_name_path_generator():\n",
        "\n",
        "  model_name = next_id(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "\n",
        "  path = \"/content/drive/MyDrive/MLDL_FederatedLearning/models/global/\" + model_name + \".pth\"\n",
        "\n",
        "  return model_name, path\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fRwHMcFs7f3E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title This function will evaluate the model.</br> The outputs are loss and accuracy\n",
        "def evaluation(model, data_loader):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  test_loss = 0\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in  data_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, prediction = torch.max(outputs.data,1)\n",
        "      loss = criterion(outputs, labels)\n",
        "      test_loss += loss.item() * labels.size(0)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (prediction == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    loss = test_loss / total\n",
        "    return accuracy, loss\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mYbWBZUS7ZCI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title `get_model` function retrieves and loads the models of filtered clients\n",
        "def get_model(paths,sample_sizes, backbone, raw_model):\n",
        "  for index in range(len(paths)):\n",
        "    state_dict = torch.load(paths.iloc[index]) # load state dict regarding the client number 'index'\n",
        "    raw_model.head.load_state_dict(state_dict) # set the state dict based on client\n",
        "    raw_model.to(device)\n",
        "    yield (raw_model,sample_sizes.iloc[index]) # this command throws model one at the time so less time and resouces will be used\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RQKVb-HGPkLn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <h2>FedAvg</h2>\n",
        "def fed_avg(df, raw_model):\n",
        "  total_samples = df[\"client_train_size\"].sum() # Calculate the total number of samples of clients wich had contributed\n",
        "  global_head = None # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"],df[\"client_train_size\"], df.iloc[0][\"backbone\"],raw_model)\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, sample_size in models:\n",
        "      if global_head is None:\n",
        "        global_head = copy.deepcopy(model.head.state_dict())\n",
        "        global_model = copy.deepcopy(model)\n",
        "        for k in global_head.keys():\n",
        "          global_head[k].zero_() # This command sets the tensor to zero\n",
        "\n",
        "      for k in global_head.keys():\n",
        "        global_head[k] += model.head.state_dict()[k] * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "\n",
        "    global_model.head.load_state_dict(global_head) # A model with modified head will be assignd\n",
        "\n",
        "  return global_model\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TT03jyl067bP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save and log global model\n",
        "def save_log_global_model(filtered_clients_data,global_model,test_loader ):\n",
        "  model_name, path = global_model_name_path_generator()\n",
        "  test_accracy, test_loss= evaluation(global_model, test_loader)\n",
        "  log_path = \"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\"\n",
        "\n",
        "  prev_global_model_name = filtered_clients_data[\"initial_model_name\"].values[0]\n",
        "  global_model_log = filtered_clients_data.drop([\"client_id\",\"train_loss\",\"client_train_size\",\"client_test_size\",\"duration\",],axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  global_model_log = global_model_log.iloc[0]\n",
        "  global_model_log[\"num_of_participants\"] = len(filtered_clients_data)\n",
        "  global_model_log[\"prev_global_model_name\"] = prev_global_model_name\n",
        "  global_model_log[\"model_name\"]= model_name\n",
        "  global_model_log[\"accuracy\"] = test_accracy\n",
        "  global_model_log[\"loss\"] = test_loss\n",
        "  global_model_log[\"time\"] = get_current_time()\n",
        "  global_model_log[\"path\"] = path\n",
        "  global_model_log[\"Measurement_criteria\"] = \"accuracy,loss\"\n",
        "  global_model_log[\"contributors\"] = list(filtered_clients_data[\"model_name\"])\n",
        "  global_model_log[\"aggregation_method\"] = \"FedAvg\"\n",
        "  global_model_log[\"momentum_vector_path\"] = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  global_model_log = pd.DataFrame(global_model_log).T\n",
        "\n",
        "  global_model_log = global_model_log[['backbone',\n",
        "                'num_of_clients',\n",
        "                'splitting_method',\n",
        "                'aggregation_method',\n",
        "                'Measurement_criteria',\n",
        "                'accuracy',\n",
        "                'loss',\n",
        "                'size_of_dataset',\n",
        "                'train_test_ratio',\n",
        "                'classes',\n",
        "                'round_number',\n",
        "                'num_of_participants',\n",
        "                'model_name',\n",
        "                'prev_global_model_name',\n",
        "                \"contributors\",\n",
        "                'path',\n",
        "                \"momentum_vector_path\",\n",
        "                'path_to_subsets',\n",
        "                'path_to_class_combs',\n",
        "                'time'\n",
        "                ]]\n",
        "\n",
        "  flag = False\n",
        "  if os.path.exists(path):\n",
        "    print(\"Model already exist\")\n",
        "    flag = True\n",
        "\n",
        "  if os.path.exists(log_path):\n",
        "    global_log_df = pd.read_csv(log_path)\n",
        "    if model_name in global_log_df[\"model_name\"].values:\n",
        "      print(\"record already exist\")\n",
        "      flag = True\n",
        "    if not flag:\n",
        "      global_model_log.to_csv(log_path, mode='a', header=False, index=False)\n",
        "  else:\n",
        "    if not flag:\n",
        "      global_model_log.to_csv(log_path, index=False, header=True)\n",
        "\n",
        "\n",
        "  if not flag:\n",
        "    torch.save(global_model.head.state_dict(),  path )\n",
        "  return global_model_log\n"
      ],
      "metadata": {
        "id": "MgNuOL2y7v6l"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Loop"
      ],
      "metadata": {
        "id": "L4BHlJ66BzL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_model_name = \"f142f936-1ed1-4dfb-b0b2-3f99aff46a89\" #@param{\"type\":\"string\"}\n",
        "\n",
        "\n",
        "dino_model = torch.hub.load('facebookresearch/dino:main', backbone)\n",
        "raw_model = DinoClassifier(dino_model=dino_model, num_classes=100, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_BVM23BB9sx",
        "outputId": "bacdf3aa-0e0e-46ba-9511-095c57ba05c3",
        "cellView": "form"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "load_data = True #@param{\"type\":\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if load_data:\n",
        "\n",
        "  initial_model_log_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "  path_to_subsets =initial_model_log_df[initial_model_log_df[\"model_name\"] == seed_model_name][\"path_to_subsets\"].values[0]\n",
        "  path_to_class_combs =initial_model_log_df[initial_model_log_df[\"model_name\"] == seed_model_name][\"path_to_class_combs\"].values[0]\n",
        "\n",
        "  initial_model_name= get_lastgen_model_name(seed_model_name=seed_model_name)\n",
        "  initial_model_path = initial_model_log_df[initial_model_log_df[\"model_name\"] == initial_model_name][\"path\"].values[0]\n",
        "\n",
        "\n",
        "\n",
        "  dino_model = torch.hub.load('facebookresearch/dino:main', backbone)\n",
        "  initial_model = DinoClassifier(dino_model=dino_model, num_classes=100, device=device)\n",
        "  initial_model.head.load_state_dict(torch.load(initial_model_path))\n",
        "\n",
        "  client_data = torch.load(path_to_subsets, weights_only=False)\n",
        "  if not spliting_method == \"i.i.d. sharing\":\n",
        "    class_combs = torch.load(path_to_class_combs)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "56FLr8HaszZz",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6f09fc-a97c-4603-dece-82b39645f8d2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Whole FL Circle\n",
        "from google.colab import output\n",
        "report_log = None\n",
        "round_log = \"\"\n",
        "while True:\n",
        "\n",
        "\n",
        "\n",
        "  initial_model_name= get_lastgen_model_name(seed_model_name=seed_model_name)\n",
        "  initial_model_log_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "  initial_model_round_num = initial_model_log_df[initial_model_log_df[\"model_name\"] == initial_model_name][\"round_number\"].values[0]\n",
        "\n",
        "  if initial_model_round_num >= 20:\n",
        "\n",
        "    break\n",
        "\n",
        "  print(f\"Seed Model name: {seed_model_name} , Initial model name: {initial_model_name} ,  Round number: {initial_model_round_num}\")\n",
        "\n",
        "\n",
        "\n",
        "  clients_round(n_clients,initial_model_name,selection_percentage,spliting_method,client_data,raw_model)\n",
        "  filtered_clients_data = get_clients(initial_model_name)\n",
        "\n",
        "  if len(filtered_clients_data) >= n_clients / selection_percentage :\n",
        "    global_model = fed_avg(filtered_clients_data,raw_model)\n",
        "    report_log = save_log_global_model(filtered_clients_data,global_model,test_loader)\n",
        "  output.clear()\n",
        "  round_log += f\"round {initial_model_round_num} >> loss: {report_log['loss'].values[0]}, accuracy: {report_log['accuracy'].values[0]}\\n\"\n",
        "  print(round_log)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30dkSVoAClg",
        "outputId": "b1bcfd7f-c6a6-45f8-f184-b07c988d561d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "round 0 >> loss: 6.9073562316894535, accuracy: 1.1\n",
            "round 1 >> loss: 6.579533848571777, accuracy: 1.32\n",
            "round 2 >> loss: 6.338784892272949, accuracy: 1.33\n",
            "round 3 >> loss: 6.180479454803467, accuracy: 1.47\n",
            "round 4 >> loss: 6.0245173583984375, accuracy: 1.6\n",
            "round 5 >> loss: 5.896428373718262, accuracy: 1.83\n",
            "round 6 >> loss: 5.797027098083496, accuracy: 2.03\n",
            "round 7 >> loss: 5.708056669616699, accuracy: 2.19\n",
            "round 8 >> loss: 5.604754831695557, accuracy: 2.48\n",
            "round 9 >> loss: 5.527164667510986, accuracy: 2.6\n",
            "round 10 >> loss: 5.442627429962158, accuracy: 3.0\n",
            "round 11 >> loss: 5.365307500457764, accuracy: 3.23\n",
            "round 12 >> loss: 5.288673429870605, accuracy: 3.36\n",
            "round 13 >> loss: 5.220307563781739, accuracy: 4.17\n",
            "round 14 >> loss: 5.151196535491944, accuracy: 4.23\n",
            "round 15 >> loss: 5.080988056945801, accuracy: 4.46\n",
            "round 16 >> loss: 5.006019664001465, accuracy: 4.83\n",
            "round 17 >> loss: 4.944290938568115, accuracy: 5.1\n",
            "round 18 >> loss: 4.883437657928467, accuracy: 5.56\n",
            "round 19 >> loss: 4.819920746612548, accuracy: 5.94\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fu0Iz0LDlRDK",
        "M9hv0ik3jZ-8",
        "t4oXrqMHwAit",
        "bVtH-qLIrAeh",
        "l66ikAyqfg4f"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}